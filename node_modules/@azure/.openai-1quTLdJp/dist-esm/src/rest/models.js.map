{"version":3,"file":"models.js","sourceRoot":"","sources":["../../../src/rest/models.ts"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC","sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\n/** The configuration information for an audio transcription request. */\nexport interface AudioTranscriptionOptions {\n  /**\n   * The audio data to transcribe. This must be the binary content of a file in one of the supported media formats:\n   *  flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm.\n   */\n  file: string;\n  /** The optional filename or descriptive identifier to associate with with the audio data. */\n  filename?: string;\n  /** The requested format of the transcription response data, which will influence the content and detail of the result. */\n  response_format?: AudioTranscriptionFormat;\n  /**\n   * The primary spoken language of the audio data to be transcribed, supplied as a two-letter ISO-639-1 language code\n   * such as 'en' or 'fr'.\n   * Providing this known input language is optional but may improve the accuracy and/or latency of transcription.\n   */\n  language?: string;\n  /**\n   * An optional hint to guide the model's style or continue from a prior audio segment. The written language of the\n   * prompt should match the primary spoken language of the audio data.\n   */\n  prompt?: string;\n  /**\n   * The sampling temperature, between 0 and 1.\n   * Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n   * If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n  /** The model to use for this transcription request. */\n  model?: string;\n}\n\n/** The configuration information for an audio translation request. */\nexport interface AudioTranslationOptions {\n  /**\n   * The audio data to translate. This must be the binary content of a file in one of the supported media formats:\n   *  flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm.\n   */\n  file: string;\n  /** The optional filename or descriptive identifier to associate with with the audio data. */\n  filename?: string;\n  /** The requested format of the translation response data, which will influence the content and detail of the result. */\n  response_format?: AudioTranslationFormat;\n  /**\n   * An optional hint to guide the model's style or continue from a prior audio segment. The written language of the\n   * prompt should match the primary spoken language of the audio data.\n   */\n  prompt?: string;\n  /**\n   * The sampling temperature, between 0 and 1.\n   * Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n   * If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n  /** The model to use for this translation request. */\n  model?: string;\n}\n\n/**\n * The configuration information for a completions request.\n * Completions support a wide variety of tasks and generate text that continues from or \"completes\"\n * provided prompt data.\n */\nexport interface CompletionsOptions {\n  /** The prompts to generate completions from. */\n  prompt: string[];\n  /** The maximum number of tokens to generate. */\n  max_tokens?: number;\n  /**\n   * The sampling temperature to use that controls the apparent creativity of generated completions.\n   * Higher values will make output more random while lower values will make results more focused\n   * and deterministic.\n   * It is not recommended to modify temperature and top_p for the same completions request as the\n   * interaction of these two settings is difficult to predict.\n   */\n  temperature?: number;\n  /**\n   * An alternative to sampling with temperature called nucleus sampling. This value causes the\n   * model to consider the results of tokens with the provided probability mass. As an example, a\n   * value of 0.15 will cause only the tokens comprising the top 15% of probability mass to be\n   * considered.\n   * It is not recommended to modify temperature and top_p for the same completions request as the\n   * interaction of these two settings is difficult to predict.\n   */\n  top_p?: number;\n  /**\n   * A map between GPT token IDs and bias scores that influences the probability of specific tokens\n   * appearing in a completions response. Token IDs are computed via external tokenizer tools, while\n   * bias scores reside in the range of -100 to 100 with minimum and maximum values corresponding to\n   * a full ban or exclusive selection of a token, respectively. The exact behavior of a given bias\n   * score varies by model.\n   */\n  logit_bias?: Record<string, number>;\n  /**\n   * An identifier for the caller or end user of the operation. This may be used for tracking\n   * or rate-limiting purposes.\n   */\n  user?: string;\n  /**\n   * The number of completions choices that should be generated per provided prompt as part of an\n   * overall completions response.\n   * Because this setting can generate many completions, it may quickly consume your token quota.\n   * Use carefully and ensure reasonable settings for max_tokens and stop.\n   */\n  n?: number;\n  /**\n   * A value that controls the emission of log probabilities for the provided number of most likely\n   * tokens within a completions response.\n   */\n  logprobs?: number;\n  /** The suffix that comes after a completion of inserted text */\n  suffix?: string;\n  /**\n   * A value specifying whether completions responses should include input prompts as prefixes to\n   * their generated output.\n   */\n  echo?: boolean;\n  /** A collection of textual sequences that will end completions generation. */\n  stop?: string[];\n  /**\n   * A value that influences the probability of generated tokens appearing based on their existing\n   * presence in generated text.\n   * Positive values will make tokens less likely to appear when they already exist and increase the\n   * model's likelihood to output new topics.\n   */\n  presence_penalty?: number;\n  /**\n   * A value that influences the probability of generated tokens appearing based on their cumulative\n   * frequency in generated text.\n   * Positive values will make tokens less likely to appear as their frequency increases and\n   * decrease the likelihood of the model repeating the same statements verbatim.\n   */\n  frequency_penalty?: number;\n  /**\n   * A value that controls how many completions will be internally generated prior to response\n   * formulation.\n   * When used together with n, best_of controls the number of candidate completions and must be\n   * greater than n.\n   * Because this setting can generate many completions, it may quickly consume your token quota.\n   * Use carefully and ensure reasonable settings for max_tokens and stop.\n   */\n  best_of?: number;\n  /** A value indicating whether chat completions should be streamed for this request. */\n  stream?: boolean;\n  /**\n   * The model name to provide as part of this completions request.\n   * Not applicable to Azure OpenAI, where deployment information should be included in the Azure\n   * resource URI that's connected to.\n   */\n  model?: string;\n}\n\n/**\n * The configuration information for a chat completions request.\n * Completions support a wide variety of tasks and generate text that continues from or \"completes\"\n * provided prompt data.\n */\nexport interface ChatCompletionsOptions {\n  /**\n   * The collection of context messages associated with this chat completions request.\n   * Typical usage begins with a chat message for the System role that provides instructions for\n   * the behavior of the assistant, followed by alternating messages between the User and\n   * Assistant roles.\n   */\n  messages: Array<ChatRequestMessage>;\n  /** A list of functions the model may generate JSON inputs for. */\n  functions?: Array<FunctionDefinition>;\n  /**\n   * Controls how the model responds to function calls. \"none\" means the model does not call a function,\n   * and responds to the end-user. \"auto\" means the model can pick between an end-user or calling a function.\n   *  Specifying a particular function via `{\"name\": \"my_function\"}` forces the model to call that function.\n   *  \"none\" is the default when no functions are present. \"auto\" is the default if functions are present.\n   */\n  function_call?: FunctionCallPreset | FunctionName;\n  /** The maximum number of tokens to generate. */\n  max_tokens?: number;\n  /**\n   * The sampling temperature to use that controls the apparent creativity of generated completions.\n   * Higher values will make output more random while lower values will make results more focused\n   * and deterministic.\n   * It is not recommended to modify temperature and top_p for the same completions request as the\n   * interaction of these two settings is difficult to predict.\n   */\n  temperature?: number;\n  /**\n   * An alternative to sampling with temperature called nucleus sampling. This value causes the\n   * model to consider the results of tokens with the provided probability mass. As an example, a\n   * value of 0.15 will cause only the tokens comprising the top 15% of probability mass to be\n   * considered.\n   * It is not recommended to modify temperature and top_p for the same completions request as the\n   * interaction of these two settings is difficult to predict.\n   */\n  top_p?: number;\n  /**\n   * A map between GPT token IDs and bias scores that influences the probability of specific tokens\n   * appearing in a completions response. Token IDs are computed via external tokenizer tools, while\n   * bias scores reside in the range of -100 to 100 with minimum and maximum values corresponding to\n   * a full ban or exclusive selection of a token, respectively. The exact behavior of a given bias\n   * score varies by model.\n   */\n  logit_bias?: Record<string, number>;\n  /**\n   * An identifier for the caller or end user of the operation. This may be used for tracking\n   * or rate-limiting purposes.\n   */\n  user?: string;\n  /**\n   * The number of chat completions choices that should be generated for a chat completions\n   * response.\n   * Because this setting can generate many completions, it may quickly consume your token quota.\n   * Use carefully and ensure reasonable settings for max_tokens and stop.\n   */\n  n?: number;\n  /** A collection of textual sequences that will end completions generation. */\n  stop?: string[];\n  /**\n   * A value that influences the probability of generated tokens appearing based on their existing\n   * presence in generated text.\n   * Positive values will make tokens less likely to appear when they already exist and increase the\n   * model's likelihood to output new topics.\n   */\n  presence_penalty?: number;\n  /**\n   * A value that influences the probability of generated tokens appearing based on their cumulative\n   * frequency in generated text.\n   * Positive values will make tokens less likely to appear as their frequency increases and\n   * decrease the likelihood of the model repeating the same statements verbatim.\n   */\n  frequency_penalty?: number;\n  /** A value indicating whether chat completions should be streamed for this request. */\n  stream?: boolean;\n  /**\n   * The model name to provide as part of this completions request.\n   * Not applicable to Azure OpenAI, where deployment information should be included in the Azure\n   * resource URI that's connected to.\n   */\n  model?: string;\n  /**\n   *   The configuration entries for Azure OpenAI chat extensions that use them.\n   *   This additional specification is only compatible with Azure OpenAI.\n   */\n  data_sources?: Array<AzureChatExtensionConfiguration>;\n  /** If provided, the configuration options for available Azure OpenAI chat enhancements. */\n  enhancements?: AzureChatEnhancementConfiguration;\n  /**\n   * If specified, the system will make a best effort to sample deterministically such that repeated requests with the\n   * same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the\n   * system_fingerprint response parameter to monitor changes in the backend.\"\n   */\n  seed?: number;\n  /** Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`. This option is currently not available on the `gpt-4-vision-preview` model. */\n  logprobs?: boolean | null;\n  /** An integer between 0 and 5 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used. */\n  top_logprobs?: number | null;\n  /** An object specifying the format that the model must output. Used to enable JSON mode. */\n  response_format?: ChatCompletionsResponseFormat;\n  /** The available tool definitions that the chat completions request can use, including caller-defined functions. */\n  tools?: Array<ChatCompletionsToolDefinition>;\n  /** If specified, the model will configure which of the provided tools it can use for the chat completions response. */\n  tool_choice?: ChatCompletionsToolSelectionPreset | ChatCompletionsNamedToolSelection;\n}\n\n/** An abstract representation of a chat message as provided in a request. */\nexport interface ChatRequestMessageParent {\n  role: ChatRole;\n}\n\n/**\n * A request chat message containing system instructions that influence how the model will generate a chat completions\n * response.\n */\nexport interface ChatRequestSystemMessage extends ChatRequestMessageParent {\n  /** The chat role associated with this message, which is always 'system' for system messages. */\n  role: \"system\";\n  /** The contents of the system message. */\n  content: string;\n  /** An optional name for the participant. */\n  name?: string;\n}\n\n/** A request chat message representing user input to the assistant. */\nexport interface ChatRequestUserMessage extends ChatRequestMessageParent {\n  /** The chat role associated with this message, which is always 'user' for user messages. */\n  role: \"user\";\n  /** The contents of the user message, with available input types varying by selected model. */\n  content: string | Array<ChatMessageContentItem>;\n  /** An optional name for the participant. */\n  name?: string;\n}\n\n/** An abstract representation of a structured content item within a chat message. */\nexport interface ChatMessageContentItemParent {\n  type: string;\n}\n\n/** A structured chat content item containing plain text. */\nexport interface ChatMessageTextContentItem extends ChatMessageContentItemParent {\n  /** The discriminated object type: always 'text' for this type. */\n  type: \"text\";\n  /** The content of the message. */\n  text: string;\n}\n\n/** A structured chat content item containing an image reference. */\nexport interface ChatMessageImageContentItem extends ChatMessageContentItemParent {\n  /** The discriminated object type: always 'image_url' for this type. */\n  type: \"image_url\";\n  /** An internet location, which must be accessible to the model,from which the image may be retrieved. */\n  image_url: ChatMessageImageUrl;\n}\n\n/** An internet location from which the model may retrieve an image. */\nexport interface ChatMessageImageUrl {\n  /** The URL of the image. */\n  url: string;\n  /**\n   * The evaluation quality setting to use, which controls relative prioritization of speed, token consumption, and\n   * accuracy.\n   */\n  detail?: ChatMessageImageDetailLevel;\n}\n\n/** A request chat message representing response or action from the assistant. */\nexport interface ChatRequestAssistantMessage extends ChatRequestMessageParent {\n  /** The chat role associated with this message, which is always 'assistant' for assistant messages. */\n  role: \"assistant\";\n  /** The content of the message. */\n  content: string | null;\n  /** An optional name for the participant. */\n  name?: string;\n  /**\n   * The tool calls that must be resolved and have their outputs appended to subsequent input messages for the chat\n   * completions request to resolve as configured.\n   */\n  tool_calls?: Array<ChatCompletionsToolCall>;\n  /**\n   * The function call that must be resolved and have its output appended to subsequent input messages for the chat\n   * completions request to resolve as configured.\n   */\n  function_call?: FunctionCall;\n}\n\n/**\n * An abstract representation of a tool call that must be resolved in a subsequent request to perform the requested\n * chat completion.\n */\nexport interface ChatCompletionsToolCallParent {\n  /** The ID of the tool call. */\n  id: string;\n  type: string;\n}\n\n/**\n * A tool call to a function tool, issued by the model in evaluation of a configured function tool, that represents\n * a function invocation needed for a subsequent chat completions request to resolve.\n */\nexport interface ChatCompletionsFunctionToolCall extends ChatCompletionsToolCallParent {\n  /** The type of tool call, in this case always 'function'. */\n  type: \"function\";\n  /** The details of the function invocation requested by the tool call. */\n  function: FunctionCall;\n}\n\n/** The name and arguments of a function that should be called, as generated by the model. */\nexport interface FunctionCall {\n  /** The name of the function to call. */\n  name: string;\n  /**\n   * The arguments to call the function with, as generated by the model in JSON format.\n   * Note that the model does not always generate valid JSON, and may hallucinate parameters\n   * not defined by your function schema. Validate the arguments in your code before calling\n   * your function.\n   */\n  arguments: string;\n}\n\n/** A request chat message representing requested output from a configured tool. */\nexport interface ChatRequestToolMessage extends ChatRequestMessageParent {\n  /** The chat role associated with this message, which is always 'tool' for tool messages. */\n  role: \"tool\";\n  /** The content of the message. */\n  content: string | null;\n  /** The ID of the tool call resolved by the provided content. */\n  tool_call_id: string;\n}\n\n/** A request chat message representing requested output from a configured function. */\nexport interface ChatRequestFunctionMessage extends ChatRequestMessageParent {\n  /** The chat role associated with this message, which is always 'function' for function messages. */\n  role: \"function\";\n  /** The name of the function that was called to produce output. */\n  name: string;\n  /** The output of the function as requested by the function call. */\n  content: string | null;\n}\n\n/** The definition of a caller-specified function that chat completions may invoke in response to matching user input. */\nexport interface FunctionDefinition {\n  /** The name of the function to be called. */\n  name: string;\n  /**\n   * A description of what the function does. The model will use this description when selecting the function and\n   * interpreting its parameters.\n   */\n  description?: string;\n  /** The parameters the function accepts, described as a JSON Schema object. */\n  parameters?: unknown;\n}\n\n/**\n * A structure that specifies the exact name of a specific, request-provided function to use when processing a chat\n * completions operation.\n */\nexport interface FunctionName {\n  /** The name of the function to call. */\n  name: string;\n}\n\n/**\n *   A representation of configuration data for a single Azure OpenAI chat extension. This will be used by a chat\n *   completions request that should use Azure OpenAI chat extensions to augment the response behavior.\n *   The use of this configuration is compatible only with Azure OpenAI.\n */\nexport interface AzureChatExtensionConfigurationParent {\n  type: AzureChatExtensionType;\n}\n\n/**\n * A specific representation of configurable options for Azure Search when using it as an Azure OpenAI chat\n * extension.\n */\nexport interface AzureSearchChatExtensionConfiguration\n  extends AzureChatExtensionConfigurationParent {\n  /**\n   * The type label to use when configuring Azure OpenAI chat extensions. This should typically not be changed from its\n   * default value for Azure Cognitive Search.\n   */\n  type: \"azure_search\";\n  /** The parameters to use when configuring Azure Search. */\n  parameters: AzureSearchChatExtensionParameters;\n}\n\n/** Parameters for Azure Cognitive Search when used as an Azure OpenAI chat extension. The supported authentication types are APIKey, SystemAssignedManagedIdentity and UserAssignedManagedIdentity. */\nexport interface AzureSearchChatExtensionParameters {\n  /**\n   * The authentication method to use when accessing the defined data source.\n   * Each data source type supports a specific set of available authentication methods; please see the documentation of\n   * the data source for supported mechanisms.\n   * If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)\n   * authentication.\n   */\n  authentication?: OnYourDataAuthenticationOptions;\n  /** The configured top number of documents to feature for the configured query. */\n  top_n_documents?: number;\n  /** Whether queries should be restricted to use of indexed data. */\n  in_scope?: boolean;\n  /** The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. */\n  strictness?: number;\n  /** Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. */\n  role_information?: string;\n  /** The absolute endpoint path for the Azure Cognitive Search resource to use. */\n  endpoint: string;\n  /** The name of the index to use as available in the referenced Azure Cognitive Search resource. */\n  index_name: string;\n  /** Customized field mapping behavior to use when interacting with the search index. */\n  fields_mapping?: AzureSearchIndexFieldMappingOptions;\n  /** The query type to use with Azure Cognitive Search. */\n  query_type?: AzureSearchQueryType;\n  /** The additional semantic configuration for the query. */\n  semantic_configuration?: string;\n  /** Search filter. */\n  filter?: string;\n  /** The embedding dependency for vector search. */\n  embedding_dependency?: OnYourDataVectorizationSource;\n}\n\n/** The authentication options for Azure OpenAI On Your Data. */\nexport interface OnYourDataAuthenticationOptionsParent {\n  type: OnYourDataAuthenticationType;\n}\n\n/** The authentication options for Azure OpenAI On Your Data when using an API key. */\nexport interface OnYourDataApiKeyAuthenticationOptions\n  extends OnYourDataAuthenticationOptionsParent {\n  /** The authentication type of API key. */\n  type: \"api_key\";\n  /** The API key to use for authentication. */\n  key: string;\n}\n\n/** The authentication options for Azure OpenAI On Your Data when using a connection string. */\nexport interface OnYourDataConnectionStringAuthenticationOptions\n  extends OnYourDataAuthenticationOptionsParent {\n  /** The authentication type of connection string. */\n  type: \"connection_string\";\n  /** The connection string to use for authentication. */\n  connection_string: string;\n}\n\n/** The authentication options for Azure OpenAI On Your Data when using an Elasticsearch key and key ID pair. */\nexport interface OnYourDataKeyAndKeyIdAuthenticationOptions\n  extends OnYourDataAuthenticationOptionsParent {\n  /** The authentication type of Elasticsearch key and key ID pair. */\n  type: \"key_and_key_id\";\n  /** The key to use for authentication. */\n  key: string;\n  /** The key ID to use for authentication. */\n  key_id: string;\n}\n\n/** The authentication options for Azure OpenAI On Your Data when using an Elasticsearch encoded API key. */\nexport interface OnYourDataEncodedApiKeyAuthenticationOptions\n  extends OnYourDataAuthenticationOptionsParent {\n  /** The authentication type of Elasticsearch encoded API Key. */\n  type: \"encoded_api_key\";\n  /** The encoded API key to use for authentication. */\n  encoded_api_key: string;\n}\n\n/** The authentication options for Azure OpenAI On Your Data when using access token. */\nexport interface OnYourDataAccessTokenAuthenticationOptions\n  extends OnYourDataAuthenticationOptionsParent {\n  /** The authentication type of access token. */\n  type: \"access_token\";\n  /** The access token to use for authentication. */\n  access_token: string;\n}\n\n/** The authentication options for Azure OpenAI On Your Data when using a system-assigned managed identity. */\nexport interface OnYourDataSystemAssignedManagedIdentityAuthenticationOptions\n  extends OnYourDataAuthenticationOptionsParent {\n  /** The authentication type of system-assigned managed identity. */\n  type: \"system_assigned_managed_identity\";\n}\n\n/** The authentication options for Azure OpenAI On Your Data when using a user-assigned managed identity. */\nexport interface OnYourDataUserAssignedManagedIdentityAuthenticationOptions\n  extends OnYourDataAuthenticationOptionsParent {\n  /** The authentication type of user-assigned managed identity. */\n  type: \"user_assigned_managed_identity\";\n  /** The resource ID of the user-assigned managed identity to use for authentication. */\n  managed_identity_resource_id: string;\n}\n\n/** Optional settings to control how fields are processed when using a configured Azure Search resource. */\nexport interface AzureSearchIndexFieldMappingOptions {\n  /** The name of the index field to use as a title. */\n  title_field?: string;\n  /** The name of the index field to use as a URL. */\n  url_field?: string;\n  /** The name of the index field to use as a filepath. */\n  filepath_field?: string;\n  /** The names of index fields that should be treated as content. */\n  content_fields?: string[];\n  /** The separator pattern that content fields should use. */\n  content_fields_separator?: string;\n  /** The names of fields that represent vector data. */\n  vector_fields?: string[];\n  /** The names of fields that represent image vector data. */\n  image_vector_fields?: string[];\n}\n\n/** An abstract representation of a vectorization source for Azure OpenAI On Your Data with vector search. */\nexport interface OnYourDataVectorizationSourceParent {\n  type: OnYourDataVectorizationSourceType;\n}\n\n/**\n * The details of a a vectorization source, used by Azure OpenAI On Your Data when applying vector search, that is based\n * on a public Azure OpenAI endpoint call for embeddings.\n */\nexport interface OnYourDataEndpointVectorizationSource extends OnYourDataVectorizationSourceParent {\n  /** The type of vectorization source to use. Always 'Endpoint' for this type. */\n  type: \"endpoint\";\n  /** Specifies the resource endpoint URL from which embeddings should be retrieved. It should be in the format of https://YOUR_RESOURCE_NAME.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME/embeddings. The api-version query parameter is not allowed. */\n  endpoint: string;\n  /** Specifies the authentication options to use when retrieving embeddings from the specified endpoint. */\n  authentication: OnYourDataAuthenticationOptions;\n}\n\n/**\n * The details of a a vectorization source, used by Azure OpenAI On Your Data when applying vector search, that is based\n * on an internal embeddings model deployment name in the same Azure OpenAI resource.\n */\nexport interface OnYourDataDeploymentNameVectorizationSource\n  extends OnYourDataVectorizationSourceParent {\n  /** The type of vectorization source to use. Always 'DeploymentName' for this type. */\n  type: \"deployment_name\";\n  /** The embedding model deployment name within the same Azure OpenAI resource. This enables you to use vector search without Azure OpenAI api-key and without Azure OpenAI public network access. */\n  deployment_name: string;\n}\n\n/**\n * The details of a a vectorization source, used by Azure OpenAI On Your Data when applying vector search, that is based\n * on a search service model ID. Currently only supported by Elasticsearch®.\n */\nexport interface OnYourDataModelIdVectorizationSource extends OnYourDataVectorizationSourceParent {\n  /** The type of vectorization source to use. Always 'ModelId' for this type. */\n  type: \"model_id\";\n  /** The embedding model ID build inside the search service. Currently only supported by Elasticsearch®. */\n  model_id: string;\n}\n\n/**\n * A specific representation of configurable options for Azure Machine Learning vector index when using it as an Azure\n * OpenAI chat extension.\n */\nexport interface AzureMachineLearningIndexChatExtensionConfiguration\n  extends AzureChatExtensionConfigurationParent {\n  /**\n   * The type label to use when configuring Azure OpenAI chat extensions. This should typically not be changed from its\n   * default value for Azure Machine Learning vector index.\n   */\n  type: \"azure_ml_index\";\n  /** The parameters for the Azure Machine Learning vector index chat extension. */\n  parameters: AzureMachineLearningIndexChatExtensionParameters;\n}\n\n/** Parameters for the Azure Machine Learning vector index chat extension. The supported authentication types are AccessToken, SystemAssignedManagedIdentity and UserAssignedManagedIdentity. */\nexport interface AzureMachineLearningIndexChatExtensionParameters {\n  /**\n   * The authentication method to use when accessing the defined data source.\n   * Each data source type supports a specific set of available authentication methods; please see the documentation of\n   * the data source for supported mechanisms.\n   * If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)\n   * authentication.\n   */\n  authentication?: OnYourDataAuthenticationOptions;\n  /** The configured top number of documents to feature for the configured query. */\n  top_n_documents?: number;\n  /** Whether queries should be restricted to use of indexed data. */\n  in_scope?: boolean;\n  /** The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. */\n  strictness?: number;\n  /** Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. */\n  role_information?: string;\n  /** The resource ID of the Azure Machine Learning project. */\n  project_resource_id: string;\n  /** The Azure Machine Learning vector index name. */\n  name: string;\n  /** The version of the Azure Machine Learning vector index. */\n  version: string;\n  /** Search filter. Only supported if the Azure Machine Learning vector index is of type AzureSearch. */\n  filter?: string;\n}\n\n/**\n * A specific representation of configurable options for Azure Cosmos DB when using it as an Azure OpenAI chat\n * extension.\n */\nexport interface AzureCosmosDBChatExtensionConfiguration\n  extends AzureChatExtensionConfigurationParent {\n  /**\n   * The type label to use when configuring Azure OpenAI chat extensions. This should typically not be changed from its\n   * default value for Azure Cosmos DB.\n   */\n  type: \"azure_cosmos_db\";\n  /** The parameters to use when configuring Azure OpenAI CosmosDB chat extensions. */\n  parameters: AzureCosmosDBChatExtensionParameters;\n}\n\n/**\n * Parameters to use when configuring Azure OpenAI On Your Data chat extensions when using Azure Cosmos DB for\n * MongoDB vCore. The supported authentication type is ConnectionString.\n */\nexport interface AzureCosmosDBChatExtensionParameters {\n  /**\n   * The authentication method to use when accessing the defined data source.\n   * Each data source type supports a specific set of available authentication methods; please see the documentation of\n   * the data source for supported mechanisms.\n   * If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)\n   * authentication.\n   */\n  authentication?: OnYourDataAuthenticationOptions;\n  /** The configured top number of documents to feature for the configured query. */\n  top_n_documents?: number;\n  /** Whether queries should be restricted to use of indexed data. */\n  in_scope?: boolean;\n  /** The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. */\n  strictness?: number;\n  /** Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. */\n  role_information?: string;\n  /** The MongoDB vCore database name to use with Azure Cosmos DB. */\n  database_name: string;\n  /** The name of the Azure Cosmos DB resource container. */\n  container_name: string;\n  /** The MongoDB vCore index name to use with Azure Cosmos DB. */\n  index_name: string;\n  /** Customized field mapping behavior to use when interacting with the search index. */\n  fields_mapping: AzureCosmosDBFieldMappingOptions;\n  /** The embedding dependency for vector search. */\n  embedding_dependency: OnYourDataVectorizationSource;\n}\n\n/** Optional settings to control how fields are processed when using a configured Azure Cosmos DB resource. */\nexport interface AzureCosmosDBFieldMappingOptions {\n  /** The name of the index field to use as a title. */\n  title_field?: string;\n  /** The name of the index field to use as a URL. */\n  url_field?: string;\n  /** The name of the index field to use as a filepath. */\n  filepath_field?: string;\n  /** The names of index fields that should be treated as content. */\n  content_fields: string[];\n  /** The separator pattern that content fields should use. */\n  content_fields_separator?: string;\n  /** The names of fields that represent vector data. */\n  vector_fields: string[];\n}\n\n/**\n * A specific representation of configurable options for Elasticsearch when using it as an Azure OpenAI chat\n * extension.\n */\nexport interface ElasticsearchChatExtensionConfiguration\n  extends AzureChatExtensionConfigurationParent {\n  /**\n   * The type label to use when configuring Azure OpenAI chat extensions. This should typically not be changed from its\n   * default value for Elasticsearch®.\n   */\n  type: \"elasticsearch\";\n  /** The parameters to use when configuring Elasticsearch®. */\n  parameters: ElasticsearchChatExtensionParameters;\n}\n\n/** Parameters to use when configuring Elasticsearch® as an Azure OpenAI chat extension. The supported authentication types are KeyAndKeyId and EncodedAPIKey. */\nexport interface ElasticsearchChatExtensionParameters {\n  /**\n   * The authentication method to use when accessing the defined data source.\n   * Each data source type supports a specific set of available authentication methods; please see the documentation of\n   * the data source for supported mechanisms.\n   * If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)\n   * authentication.\n   */\n  authentication?: OnYourDataAuthenticationOptions;\n  /** The configured top number of documents to feature for the configured query. */\n  top_n_documents?: number;\n  /** Whether queries should be restricted to use of indexed data. */\n  in_scope?: boolean;\n  /** The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. */\n  strictness?: number;\n  /** Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. */\n  role_information?: string;\n  /** The endpoint of Elasticsearch®. */\n  endpoint: string;\n  /** The index name of Elasticsearch®. */\n  index_name: string;\n  /** The index field mapping options of Elasticsearch®. */\n  fields_mapping?: ElasticsearchIndexFieldMappingOptions;\n  /** The query type of Elasticsearch®. */\n  query_type?: ElasticsearchQueryType;\n  /** The embedding dependency for vector search. */\n  embedding_dependency?: OnYourDataVectorizationSource;\n}\n\n/** Optional settings to control how fields are processed when using a configured Elasticsearch® resource. */\nexport interface ElasticsearchIndexFieldMappingOptions {\n  /** The name of the index field to use as a title. */\n  title_field?: string;\n  /** The name of the index field to use as a URL. */\n  url_field?: string;\n  /** The name of the index field to use as a filepath. */\n  filepath_field?: string;\n  /** The names of index fields that should be treated as content. */\n  content_fields?: string[];\n  /** The separator pattern that content fields should use. */\n  content_fields_separator?: string;\n  /** The names of fields that represent vector data. */\n  vector_fields?: string[];\n}\n\n/**\n * A specific representation of configurable options for Pinecone when using it as an Azure OpenAI chat\n * extension.\n */\nexport interface PineconeChatExtensionConfiguration extends AzureChatExtensionConfigurationParent {\n  /**\n   * The type label to use when configuring Azure OpenAI chat extensions. This should typically not be changed from its\n   * default value for Pinecone.\n   */\n  type: \"pinecone\";\n  /** The parameters to use when configuring Azure OpenAI chat extensions. */\n  parameters: PineconeChatExtensionParameters;\n}\n\n/** Parameters for configuring Azure OpenAI Pinecone chat extensions. The supported authentication type is APIKey. */\nexport interface PineconeChatExtensionParameters {\n  /**\n   * The authentication method to use when accessing the defined data source.\n   * Each data source type supports a specific set of available authentication methods; please see the documentation of\n   * the data source for supported mechanisms.\n   * If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)\n   * authentication.\n   */\n  authentication?: OnYourDataAuthenticationOptions;\n  /** The configured top number of documents to feature for the configured query. */\n  top_n_documents?: number;\n  /** Whether queries should be restricted to use of indexed data. */\n  in_scope?: boolean;\n  /** The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. */\n  strictness?: number;\n  /** Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. */\n  role_information?: string;\n  /** The environment name of Pinecone. */\n  environment: string;\n  /** The name of the Pinecone database index. */\n  index_name: string;\n  /** Customized field mapping behavior to use when interacting with the search index. */\n  fields_mapping: PineconeFieldMappingOptions;\n  /** The embedding dependency for vector search. */\n  embedding_dependency: OnYourDataVectorizationSource;\n}\n\n/** Optional settings to control how fields are processed when using a configured Pinecone resource. */\nexport interface PineconeFieldMappingOptions {\n  /** The name of the index field to use as a title. */\n  title_field?: string;\n  /** The name of the index field to use as a URL. */\n  url_field?: string;\n  /** The name of the index field to use as a filepath. */\n  filepath_field?: string;\n  /** The names of index fields that should be treated as content. */\n  content_fields: string[];\n  /** The separator pattern that content fields should use. */\n  content_fields_separator?: string;\n}\n\n/** A representation of the available Azure OpenAI enhancement configurations. */\nexport interface AzureChatEnhancementConfiguration {\n  /** A representation of the available options for the Azure OpenAI grounding enhancement. */\n  grounding?: AzureChatGroundingEnhancementConfiguration;\n  /** A representation of the available options for the Azure OpenAI optical character recognition (OCR) enhancement. */\n  ocr?: AzureChatOCREnhancementConfiguration;\n}\n\n/** A representation of the available options for the Azure OpenAI grounding enhancement. */\nexport interface AzureChatGroundingEnhancementConfiguration {\n  /** Specifies whether the enhancement is enabled. */\n  enabled: boolean;\n}\n\n/** A representation of the available options for the Azure OpenAI optical character recognition (OCR) enhancement. */\nexport interface AzureChatOCREnhancementConfiguration {\n  /** Specifies whether the enhancement is enabled. */\n  enabled: boolean;\n}\n\n/**\n * An abstract representation of a response format configuration usable by Chat Completions. Can be used to enable JSON\n * mode.\n */\nexport interface ChatCompletionsResponseFormatParent {\n  type: string;\n}\n\n/**\n * The standard Chat Completions response format that can freely generate text and is not guaranteed to produce response\n * content that adheres to a specific schema.\n */\nexport interface ChatCompletionsTextResponseFormat extends ChatCompletionsResponseFormatParent {\n  /** The discriminated object type, which is always 'text' for this format. */\n  type: \"text\";\n}\n\n/** A response format for Chat Completions that restricts responses to emitting valid JSON objects. */\nexport interface ChatCompletionsJsonResponseFormat extends ChatCompletionsResponseFormatParent {\n  /** The discriminated object type, which is always 'json_object' for this format. */\n  type: \"json_object\";\n}\n\n/** An abstract representation of a tool that can be used by the model to improve a chat completions response. */\nexport interface ChatCompletionsToolDefinitionParent {\n  type: string;\n}\n\n/** The definition information for a chat completions function tool that can call a function in response to a tool call. */\nexport interface ChatCompletionsFunctionToolDefinition extends ChatCompletionsToolDefinitionParent {\n  /** The object name, which is always 'function'. */\n  type: \"function\";\n  /** The function definition details for the function tool. */\n  function: FunctionDefinition;\n}\n\n/** An abstract representation of an explicit, named tool selection to use for a chat completions request. */\nexport interface ChatCompletionsNamedToolSelectionParent {\n  type: string;\n}\n\n/** A tool selection of a specific, named function tool that will limit chat completions to using the named function. */\nexport interface ChatCompletionsNamedFunctionToolSelection\n  extends ChatCompletionsNamedToolSelectionParent {\n  /** The object type, which is always 'function'. */\n  type: \"function\";\n  /** The function that should be called. */\n  function: ChatCompletionsFunctionToolSelection;\n}\n\n/** A tool selection of a specific, named function tool that will limit chat completions to using the named function. */\nexport interface ChatCompletionsFunctionToolSelection {\n  /** The name of the function that should be called. */\n  name: string;\n}\n\n/** Represents the request data used to generate images. */\nexport interface ImageGenerationOptions {\n  /**\n   * The model name or Azure OpenAI model deployment name to use for image generation. If not specified, dall-e-2 will be\n   * inferred as a default.\n   */\n  model?: string;\n  /** A description of the desired images. */\n  prompt: string;\n  /**\n   * The number of images to generate.\n   * Dall-e-2 models support values between 1 and 10.\n   * Dall-e-3 models only support a value of 1.\n   */\n  n?: number;\n  /**\n   * The desired dimensions for generated images.\n   * Dall-e-2 models support 256x256, 512x512, or 1024x1024.\n   * Dall-e-3 models support 1024x1024, 1792x1024, or 1024x1792.\n   */\n  size?: ImageSize;\n  /** The format in which image generation response items should be presented. */\n  response_format?: ImageGenerationResponseFormat;\n  /**\n   * The desired image generation quality level to use.\n   * Only configurable with dall-e-3 models.\n   */\n  quality?: ImageGenerationQuality;\n  /**\n   * The desired image generation style to use.\n   * Only configurable with dall-e-3 models.\n   */\n  style?: ImageGenerationStyle;\n  /** A unique identifier representing your end-user, which can help to monitor and detect abuse. */\n  user?: string;\n}\n\n/**\n * The configuration information for an embeddings request.\n * Embeddings measure the relatedness of text strings and are commonly used for search, clustering,\n * recommendations, and other similar scenarios.\n */\nexport interface EmbeddingsOptions {\n  /**\n   * An identifier for the caller or end user of the operation. This may be used for tracking\n   * or rate-limiting purposes.\n   */\n  user?: string;\n  /**\n   * The model name to provide as part of this embeddings request.\n   * Not applicable to Azure OpenAI, where deployment information should be included in the Azure\n   * resource URI that's connected to.\n   */\n  model?: string;\n  /**\n   * Input texts to get embeddings for, encoded as a an array of strings.\n   * Each input must not exceed 2048 tokens in length.\n   *\n   * Unless you are embedding code, we suggest replacing newlines (\\\\n) in your input with a single space,\n   * as we have observed inferior results when newlines are present.\n   */\n  input: string[];\n  /** The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models. */\n  dimensions?: number;\n}\n\n/** An abstract representation of a chat message as provided in a request. */\nexport type ChatRequestMessage =\n  | ChatRequestMessageParent\n  | ChatRequestSystemMessage\n  | ChatRequestUserMessage\n  | ChatRequestAssistantMessage\n  | ChatRequestToolMessage\n  | ChatRequestFunctionMessage;\n/** An abstract representation of a structured content item within a chat message. */\nexport type ChatMessageContentItem =\n  | ChatMessageContentItemParent\n  | ChatMessageTextContentItem\n  | ChatMessageImageContentItem;\n/**\n * An abstract representation of a tool call that must be resolved in a subsequent request to perform the requested\n * chat completion.\n */\nexport type ChatCompletionsToolCall =\n  | ChatCompletionsToolCallParent\n  | ChatCompletionsFunctionToolCall;\n/**\n *   A representation of configuration data for a single Azure OpenAI chat extension. This will be used by a chat\n *   completions request that should use Azure OpenAI chat extensions to augment the response behavior.\n *   The use of this configuration is compatible only with Azure OpenAI.\n */\nexport type AzureChatExtensionConfiguration =\n  | AzureChatExtensionConfigurationParent\n  | AzureSearchChatExtensionConfiguration\n  | AzureMachineLearningIndexChatExtensionConfiguration\n  | AzureCosmosDBChatExtensionConfiguration\n  | ElasticsearchChatExtensionConfiguration\n  | PineconeChatExtensionConfiguration;\n/** The authentication options for Azure OpenAI On Your Data. */\nexport type OnYourDataAuthenticationOptions =\n  | OnYourDataAuthenticationOptionsParent\n  | OnYourDataApiKeyAuthenticationOptions\n  | OnYourDataConnectionStringAuthenticationOptions\n  | OnYourDataKeyAndKeyIdAuthenticationOptions\n  | OnYourDataEncodedApiKeyAuthenticationOptions\n  | OnYourDataAccessTokenAuthenticationOptions\n  | OnYourDataSystemAssignedManagedIdentityAuthenticationOptions\n  | OnYourDataUserAssignedManagedIdentityAuthenticationOptions;\n/** An abstract representation of a vectorization source for Azure OpenAI On Your Data with vector search. */\nexport type OnYourDataVectorizationSource =\n  | OnYourDataVectorizationSourceParent\n  | OnYourDataEndpointVectorizationSource\n  | OnYourDataDeploymentNameVectorizationSource\n  | OnYourDataModelIdVectorizationSource;\n/**\n * An abstract representation of a response format configuration usable by Chat Completions. Can be used to enable JSON\n * mode.\n */\nexport type ChatCompletionsResponseFormat =\n  | ChatCompletionsResponseFormatParent\n  | ChatCompletionsTextResponseFormat\n  | ChatCompletionsJsonResponseFormat;\n/** An abstract representation of a tool that can be used by the model to improve a chat completions response. */\nexport type ChatCompletionsToolDefinition =\n  | ChatCompletionsToolDefinitionParent\n  | ChatCompletionsFunctionToolDefinition;\n/** An abstract representation of an explicit, named tool selection to use for a chat completions request. */\nexport type ChatCompletionsNamedToolSelection =\n  | ChatCompletionsNamedToolSelectionParent\n  | ChatCompletionsNamedFunctionToolSelection;\n/** Alias for AudioTranscriptionFormat */\nexport type AudioTranscriptionFormat = string | \"json\" | \"verbose_json\" | \"text\" | \"srt\" | \"vtt\";\n/** Alias for AudioTranslationFormat */\nexport type AudioTranslationFormat = string | \"json\" | \"verbose_json\" | \"text\" | \"srt\" | \"vtt\";\n/** Alias for ChatRole */\nexport type ChatRole = string | \"system\" | \"assistant\" | \"user\" | \"function\" | \"tool\";\n/** Alias for ChatMessageImageDetailLevel */\nexport type ChatMessageImageDetailLevel = string | \"auto\" | \"low\" | \"high\";\n/** Alias for FunctionCallPreset */\nexport type FunctionCallPreset = string | \"auto\" | \"none\";\n/** Alias for AzureChatExtensionType */\nexport type AzureChatExtensionType =\n  | string\n  | \"azure_search\"\n  | \"azure_ml_index\"\n  | \"azure_cosmos_db\"\n  | \"elasticsearch\"\n  | \"pinecone\";\n/** Alias for OnYourDataAuthenticationType */\nexport type OnYourDataAuthenticationType =\n  | string\n  | \"api_key\"\n  | \"connection_string\"\n  | \"key_and_key_id\"\n  | \"encoded_api_key\"\n  | \"access_token\"\n  | \"system_assigned_managed_identity\"\n  | \"user_assigned_managed_identity\";\n/** Alias for AzureSearchQueryType */\nexport type AzureSearchQueryType =\n  | string\n  | \"simple\"\n  | \"semantic\"\n  | \"vector\"\n  | \"vector_simple_hybrid\"\n  | \"vector_semantic_hybrid\";\n/** Alias for OnYourDataVectorizationSourceType */\nexport type OnYourDataVectorizationSourceType =\n  | string\n  | \"endpoint\"\n  | \"deployment_name\"\n  | \"model_id\";\n/** Alias for ElasticsearchQueryType */\nexport type ElasticsearchQueryType = string | \"simple\" | \"vector\";\n/** Alias for ChatCompletionsToolSelectionPreset */\nexport type ChatCompletionsToolSelectionPreset = string | \"auto\" | \"none\";\n/** Alias for ImageSize */\nexport type ImageSize = string | \"256x256\" | \"512x512\" | \"1024x1024\" | \"1792x1024\" | \"1024x1792\";\n/** Alias for ImageGenerationResponseFormat */\nexport type ImageGenerationResponseFormat = string | \"url\" | \"b64_json\";\n/** Alias for ImageGenerationQuality */\nexport type ImageGenerationQuality = string | \"standard\" | \"hd\";\n/** Alias for ImageGenerationStyle */\nexport type ImageGenerationStyle = string | \"natural\" | \"vivid\";\n"]}